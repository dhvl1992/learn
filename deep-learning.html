<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learning Content</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 40px 20px;
        }

        .flashcard-container {
            max-width: 600px;
            margin: 0 auto;
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
            color: white;
            position: sticky;
            top: 20px;
            z-index: 10;
        }

        .header h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 10px;
            text-shadow: 0 2px 10px rgba(0,0,0,0.3);
        }

        .cards-container {
            display: flex;
            flex-direction: column;
            gap: 30px;
        }

        .flashcard {
            background: white;
            border-radius: 20px;
            box-shadow: 0 15px 35px rgba(0, 0, 0, 0.3);
            overflow: hidden;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .flashcard:hover {
            transform: translateY(-5px);
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.4);
        }

        .card-header {
            padding: 25px 25px 20px;
            border-bottom: 1px solid #f0f0f0;
        }

        .card-question {
            font-size: 1.4rem;
            font-weight: 700;
            color: #333;
            line-height: 1.4;
        }

        .card-image-container {
            margin: 0 -25px;
            overflow: hidden;
        }

        .card-image-container img {
            width: 100%;
            height: auto;
            max-height: 300px;
            object-fit: cover;
            display: block;
        }

        .card-body {
            padding: 0 25px 25px;
        }

        .answer-section {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            border-left: 4px solid #667eea;
        }

        .answer-label {
            color: #667eea;
            font-weight: 700;
            font-size: 0.9rem;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            margin-bottom: 12px;
        }

        .card-answer {
            font-size: 1.05rem;
            color: #444;
            line-height: 1.7;
        }

        .card-hint {
            background: linear-gradient(45deg, #e3f2fd, #f3e5f5);
            border-radius: 12px;
            padding: 15px 20px;
            margin-top: 20px;
            font-style: italic;
            color: #1976d2;
            border-left: 4px solid #2196f3;
        }

        .card-number {
            position: absolute;
            top: 15px;
            right: 15px;
            background: rgba(102, 126, 234, 0.1);
            color: #667eea;
            padding: 5px 12px;
            border-radius: 15px;
            font-size: 0.8rem;
            font-weight: 600;
        }

        /* Mobile Responsiveness */
        @media (max-width: 480px) {
            body {
                padding: 20px 15px;
            }

            .flashcard-container {
                max-width: 100%;
            }

            .header h1 {
                font-size: 2rem;
            }
            
            .card-header {
                padding: 20px 20px 15px;
                position: relative;
            }

            .card-body {
                padding: 0 20px 20px;
            }

            .card-question {
                font-size: 1.2rem;
                padding-right: 50px;
            }
            
            .card-answer {
                font-size: 1rem;
            }

            .card-image-container {
                margin: 0 -20px;
            }

            .card-image-container img {
                max-height: 200px;
            }

            .cards-container {
                gap: 20px;
            }
        }

        /* Smooth animations */
        .flashcard {
            animation: fadeInUp 0.6s ease-out;
        }

        .flashcard:nth-child(2) { animation-delay: 0.1s; }
        .flashcard:nth-child(3) { animation-delay: 0.2s; }
        .flashcard:nth-child(4) { animation-delay: 0.3s; }
        .flashcard:nth-child(5) { animation-delay: 0.4s; }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Scroll behavior */
        html {
            scroll-behavior: smooth;
        }

        .scroll-indicator {
            text-align: center;
            color: rgba(255, 255, 255, 0.7);
            font-size: 0.9rem;
            margin-top: 20px;
            font-style: italic;
        }
    </style>
</head>
<body>
    <div class="flashcard-container">
        <div class="header">
            <h1>Learning Content</h1>
        </div>

        <div class="cards-container" id="cardsContainer">
            <!-- Cards will be dynamically generated here -->
        </div>

        <div class="scroll-indicator">
            Scroll to explore all content
        </div>
    </div>

    <script>
        const flashcards = [
    {
        question: "What is deep learning and what characterizes it?",
        answer: "Deep learning is an approach to machine learning characterized by <strong>deep stacks of computations</strong>. This depth enables models to disentangle complex and hierarchical patterns in challenging real-world data, achieving <strong>human-level or superhuman performance</strong> in tasks like natural language translation, image recognition, and game playing.",
        hint: "üß† Think: Deep = many layers of computation stacked together",
        image: ""
    },
    {
        question: "What is a neuron in artificial neural networks?",
        answer: "A neuron is the <strong>fundamental unit</strong> of a neural network. It has multiple weighted inputs and a bias that combine to produce a numerical output.<br><br><strong>Formula:</strong> y = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + ... + w‚Çôx‚Çô + b<br><br>Think of it like <strong>Excel's SUMPRODUCT function</strong> - multiply each input by its weight and sum them all up.",
        hint: "‚ö° Like SUMPRODUCT in Excel - weighted inputs plus bias",
        image: ""
    },
    {
        question: "How do weights and bias work in a neuron?",
        answer: "<strong>Weights determine input importance:</strong><br>‚Ä¢ Large positive = very important positive correlation<br>‚Ä¢ Large negative = important inverse correlation<br>‚Ä¢ Small values = less important<br><br><strong>Bias provides direction correction</strong>, pushing the neuron's output in a certain direction<br><br><strong>Key:</strong> Higher absolute weight = Higher importance regardless of sign",
        hint: "‚öñÔ∏è Weights = importance, Bias = direction adjustment",
        image: ""
    },
    {
        question: "Describe the visual structure of an artificial neuron",
        answer: "A neuron is represented as a <strong>center circle connected to all input values</strong>. The connecting lines have weight values. It performs a <strong>weighted sum</strong> where higher weights have more influence. The result is summed in the center to produce the output.<br><br>It's exactly like doing <strong>SUMPRODUCT in Excel</strong>.",
        hint: "üîµ Center circle with weighted connections - like Excel SUMPRODUCT",
        image: ""
    },
    {
        question: "What is a layer in neural networks?",
        answer: "A layer is <strong>multiple neurons at the same level</strong>, all using the same activation function. If you set <code>units=4</code> in Keras, you get one layer with <strong>4 neurons at the same level</strong>.<br><br>Networks are built by <strong>stacking multiple layers</strong>.",
        hint: "üè¢ Layer = floor of building with multiple rooms (neurons)",
        image: ""
    },
    {
        question: "What are hidden layers and why are they crucial?",
        answer: "Hidden layers are layers <strong>between input and output layers</strong>. They allow neural networks to learn <strong>complex, non-linear relationships</strong> by stacking multiple linear units with activation functions.<br><br><strong>Without hidden layers:</strong> Only linear relationships possible<br><strong>With hidden layers:</strong> Complex patterns and non-linear relationships",
        hint: "üîó Hidden layers = the magic for learning complex patterns",
        image: ""
    },
    {
        question: "What is ReLU and why is it commonly used?",
        answer: "<strong>ReLU (Rectified Linear Unit):</strong> max(0, x)<br><br>Outputs the input if positive, otherwise 0.<br><br><strong>Why popular:</strong><br>‚Ä¢ Computationally efficient<br>‚Ä¢ Helps with vanishing gradient problems<br>‚Ä¢ Enables learning non-linear patterns<br>‚Ä¢ Simple but effective",
        hint: "üöÄ ReLU: Positive values pass through, negative becomes zero",
        image: ""
    },
    {
        question: "When should you use different activation functions?",
        answer: "<strong>Function by use case:</strong><br>‚Ä¢ <strong>ELU:</strong> Smooth for negative values, can output negatives<br>‚Ä¢ <strong>SELU:</strong> Self-normalizing, good for deep networks<br>‚Ä¢ <strong>Swish:</strong> Smooth, non-monotonic, can outperform ReLU<br>‚Ä¢ <strong>Sigmoid:</strong> Output layer for binary classification (0-1 probability)<br>‚Ä¢ <strong>Softmax:</strong> Output layer for multi-class classification<br>‚Ä¢ <strong>Linear/None:</strong> Output layer for regression",
        hint: "üéõÔ∏è Choose activation based on layer position and task type",
        image: ""
    },
    {
        question: "How do you create neural networks in Keras?",
        answer: "Use <strong>keras.Sequential</strong> for linear layer stacks:<br><br><code>from tensorflow import keras<br>from tensorflow.keras import layers<br><br>model = keras.Sequential([<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(units=4, activation='relu', input_shape=[3]),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(units=7, activation='relu'),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(units=1)  # output layer<br>])</code>",
        hint: "üìö Sequential = simple stack of layers, one after another",
        image: ""
    },
    {
        question: "What does 'units' mean in Keras Dense layers?",
        answer: "<strong>Units</strong> specifies the <strong>number of neurons at the OUTPUT</strong> of that layer. Each neuron outputs a single value.<br><br><strong>Example:</strong> If you have <code>input_shape=[3]</code> and first layer has <code>units=128</code>, you go from <strong>3 inputs to 128 outputs</strong>, and the next layer starts with 128 inputs.",
        hint: "üî¢ Units = number of output neurons from that layer",
        image: ""
    },
    {
        question: "How does input specification work in Keras vs PyTorch?",
        answer: "<strong>Keras:</strong> Only specify <code>input_shape</code> for the first layer. Subsequent layers automatically calculate dimensions from previous outputs.<br><br><strong>PyTorch:</strong> Must explicitly specify input dimensions for every layer.<br><br><strong>Benefit:</strong> Keras is more convenient for sequential architectures.",
        hint: "üîß Keras = auto-calculate dimensions, PyTorch = manual specification",
        image: ""
    },
    {
        question: "What coding style improves code readability?",
        answer: "Write <strong>explicit code</strong> rather than abstract imports:<br><br><strong>Good:</strong> <code>keras.models.Sequential()</code> and <code>keras.layers.Dense()</code><br><strong>Less clear:</strong> Direct imports that hide the source<br><br><strong>Benefit:</strong> When reading code later, you immediately know where functions come from.",
        hint: "üíª Explicit imports = clear code origin and better readability",
        image: ""
    },
    {
        question: "What is SGD in simple terms?",
        answer: "SGD is <strong>'random error minimization'</strong>:<br><br>‚Ä¢ <strong>Stochastic:</strong> Randomly pick data points<br>‚Ä¢ <strong>Gradient:</strong> Find direction on the error curve<br>‚Ä¢ <strong>Descent:</strong> Always go toward lower error<br><br>It's like a <strong>ball rolling down to the lowest point</strong> of a curve where error is minimum.",
        hint: "üèÄ Like a ball rolling down to find the lowest error point",
        image: ""
    },
    {
        question: "How does SGD work step-by-step?",
        answer: "<strong>SGD Training Process:</strong><br><br>1. Randomly pick a data point (minibatch)<br>2. Make prediction<br>3. Calculate error<br>4. Use derivatives to find direction to reduce error<br>5. Adjust all weights toward lower error<br>6. Repeat with next random point<br><br>This happens <strong>thousands of times</strong> across multiple epochs.",
        hint: "üîÑ Pick ‚Üí Predict ‚Üí Calculate ‚Üí Adjust ‚Üí Repeat thousands of times",
        image: ""
    },
    {
        question: "Define minibatch, epoch, and the role of derivatives in training",
        answer: "<strong>Key training terminology:</strong><br><br>‚Ä¢ <strong>Minibatch/Batch:</strong> Small random sample of training data used in one iteration<br>‚Ä¢ <strong>Epoch:</strong> One complete pass through entire training dataset<br>‚Ä¢ <strong>Derivatives:</strong> Tell us direction to move on error curve (Newton's calculus foundation)",
        hint: "üéØ Batch = sample, Epoch = full pass, Derivatives = direction finder",
        image: ""
    },
    {
        question: "How do you choose loss functions for different problems?",
        answer: "<strong>Loss functions by problem type:</strong><br><br><strong>Regression (continuous values):</strong><br>‚Ä¢ MAE (robust to outliers)<br>‚Ä¢ MSE (penalizes large errors)<br>‚Ä¢ Huber (combines both)<br><br><strong>Binary Classification:</strong> Binary crossentropy<br><strong>Multi-class Classification:</strong> Categorical crossentropy<br><br><strong>Rule:</strong> Different problems need different mathematical tools to measure error.",
        hint: "üéØ Match loss function to problem type - different tools for different jobs",
        image: ""
    },
    {
        question: "Compare SGD and Adam optimizers",
        answer: "<strong>SGD vs Adam:</strong><br><br><strong>SGD:</strong><br>‚Ä¢ Simple, fixed learning rate<br>‚Ä¢ Reliable but can be slow<br><br><strong>Adam:</strong><br>‚Ä¢ Adaptive learning rates<br>‚Ä¢ Faster convergence<br>‚Ä¢ Combines momentum with adaptation<br><br><strong>Generally:</strong> Adam preferred for most applications, SGD for specific cases requiring stability.",
        hint: "üèÉ‚Äç‚ôÇÔ∏è Adam = smarter, adaptive SGD for faster training",
        image: ""
    },
    {
        question: "How do you compile a Keras model for training?",
        answer: "<strong>Model compilation syntax:</strong><br><br><code>model.compile(<br>&nbsp;&nbsp;&nbsp;&nbsp;optimizer='adam',<br>&nbsp;&nbsp;&nbsp;&nbsp;loss='mae',  # or appropriate loss function<br>&nbsp;&nbsp;&nbsp;&nbsp;metrics=['mae']  # or ['binary_accuracy'] for classification<br>)</code><br><br>Specify <strong>optimizer</strong>, <strong>loss function</strong>, and <strong>metrics</strong> to track.",
        hint: "‚öôÔ∏è Compile = configure the training process (optimizer + loss + metrics)",
        image: ""
    },
    {
        question: "What is overfitting and how do you identify it?",
        answer: "<strong>Overfitting:</strong> Model learns training data too well, including noise and dataset-specific patterns.<br><br><strong>Signs:</strong><br>‚Ä¢ High training accuracy but poor validation performance<br>‚Ä¢ Training loss continues decreasing while validation loss starts increasing<br>‚Ä¢ Large gap between training and validation metrics",
        hint: "üìàüìâ Good on training, bad on validation = overfitting",
        image: ""
    },
    {
        question: "What is underfitting and its characteristics?",
        answer: "<strong>Underfitting:</strong> Model is too simple to capture underlying data patterns.<br><br><strong>Signs:</strong><br>‚Ä¢ Poor performance on both training AND validation sets<br>‚Ä¢ Loss plateaus at high values for both datasets<br>‚Ä¢ Model seems too simple for task complexity",
        hint: "üò¥ Poor performance everywhere = underfitting (too simple)",
        image: ""
    },
    {
        question: "How can you visualize different fitting scenarios?",
        answer: "<strong>Visual understanding of fitting:</strong><br><br>‚Ä¢ <strong>Proper fitting:</strong> Smooth curve capturing general data trends<br>‚Ä¢ <strong>Overfitting:</strong> Curve going through every point, including noise and tiny deviations<br>‚Ä¢ <strong>Underfitting:</strong> Overly simple curve (like straight line) for complex data patterns",
        hint: "üìä Smooth curve = good, through every point = overfitting, too simple = underfitting",
        image: ""
    },
    {
        question: "What is network capacity and what determines it?",
        answer: "<strong>Network capacity:</strong> The ability to learn complex relationships, determined by:<br><br>1. <strong>Width:</strong> More neurons per layer (good for linear relationships - 'more manpower')<br>2. <strong>Depth:</strong> More layers (good for nonlinear relationships - 'more management levels')<br><br>More capacity = more intelligence to learn complex patterns.",
        hint: "üß† Capacity = intelligence level, Width = manpower, Depth = management levels",
        image: ""
    },
    {
        question: "How does a corporate hierarchy explain network depth?",
        answer: "<strong>Corporate hierarchy analogy:</strong><br><br>‚Ä¢ <strong>Layer 1:</strong> Ground-level employees (basic processing)<br>‚Ä¢ <strong>Layer 2:</strong> Managers (access to more info, bigger picture)<br>‚Ä¢ <strong>Layer 3+:</strong> Higher management/CEO (sees everything, handles complex patterns)<br><br><strong>Depth = Complicated intelligence:</strong> More layers = more complex problem-solving ability",
        hint: "üè¢ Deeper network = higher management levels = more complex decisions",
        image: ""
    },
    {
        question: "What is early stopping and why is it crucial?",
        answer: "<strong>Early stopping:</strong> Monitors validation performance and stops training when validation loss starts increasing while training loss continues decreasing.<br><br>It's like <strong>'quit while you're ahead'</strong> - stop at peak performance before overfitting ruins the model. Don't keep going like Game of Thrones.",
        hint: "üõë Stop at the sweet spot - quit while you're ahead!",
        image: ""
    },
    {
        question: "What is dropout and how does it prevent overfitting?",
        answer: "<strong>Dropout:</strong> Randomly sets a fraction of neurons to 0 during training, preventing the network from becoming too dependent on specific neurons.<br><br><strong>Benefits:</strong><br>‚Ä¢ Forces learning of more robust, generalizable features<br>‚Ä¢ Creates ensemble effect<br>‚Ä¢ Applied only during training, not inference",
        hint: "üé≤ Randomly 'turn off' neurons to prevent over-dependence",
        image: ""
    },
    {
        question: "How do you add dropout to a Keras model?",
        answer: "<strong>Dropout implementation:</strong><br><br><code>model = keras.Sequential([<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(512, activation='relu'),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dropout(0.3),  # 30% dropout rate<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(1)<br>])</code><br><br>Dropout layer placed <strong>after Dense layers</strong>.",
        hint: "üíß Add Dropout layer after Dense with rate (0.3 = 30% dropout)",
        image: ""
    },
    {
        question: "What is batch normalization and what problems does it solve?",
        answer: "<strong>Batch normalization:</strong> Normalizes inputs to each layer, making training more stable and faster.<br><br><strong>Problems it solves:</strong><br>‚Ä¢ Internal covariate shift<br>‚Ä¢ Vanishing/exploding gradients<br>‚Ä¢ Allows higher learning rates<br>‚Ä¢ Acts as mild regularization",
        hint: "üîÑ Normalize inputs = stable, faster training",
        image: ""
    },
    {
        question: "What's the correct order for combining Dense, BatchNorm, Activation, and Dropout?",
        answer: "<strong>Standard order:</strong> Dense ‚Üí BatchNormalization ‚Üí Activation ‚Üí Dropout<br><br><code>layers.Dense(units),<br>layers.BatchNormalization(),<br>layers.Activation('relu'),<br>layers.Dropout(rate)</code><br><br>This order optimizes training stability and regularization effectiveness.",
        hint: "üî¢ Remember: Dense ‚Üí BatchNorm ‚Üí Activation ‚Üí Dropout",
        image: ""
    },
    {
        question: "How do you set up binary classification in neural networks?",
        answer: "<strong>Binary classification setup:</strong><br><br>‚Ä¢ <strong>Output layer:</strong> 1 neuron with sigmoid activation<br>‚Ä¢ <strong>Loss function:</strong> Binary crossentropy<br>‚Ä¢ <strong>Metrics:</strong> Binary accuracy<br>‚Ä¢ <strong>Output interpretation:</strong> Probability of positive class (0-1)",
        hint: "üéØ 1 neuron + sigmoid + binary_crossentropy = binary classification",
        image: ""
    },
    {
        question: "Create a complete binary classification model in Keras",
        answer: "<strong>Complete binary classification model:</strong><br><br><code>model = keras.Sequential([<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(4, activation='relu', input_shape=[33]),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(4, activation='relu'),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(1, activation='sigmoid')  # sigmoid for probability<br>])<br><br>model.compile(<br>&nbsp;&nbsp;&nbsp;&nbsp;optimizer='adam',<br>&nbsp;&nbsp;&nbsp;&nbsp;loss='binary_crossentropy',<br>&nbsp;&nbsp;&nbsp;&nbsp;metrics=['binary_accuracy']<br>)</code>",
        hint: "üîß Key components: sigmoid output + binary_crossentropy loss",
        image: ""
    },
    {
        question: "How do accuracy and loss relate to each other?",
        answer: "<strong>Accuracy vs Loss relationship:</strong><br><br>Accuracy is the ratio of correct predictions to total predictions. Accuracy and error/loss have an <strong>inverse relationship</strong> - higher accuracy means lower error.<br><br><strong>Perfect case:</strong> 100% accuracy means the network learned perfectly (minimum error).",
        hint: "‚öñÔ∏è High accuracy = Low loss (inverse relationship)",
        image: ""
    },
    {
        question: "How do you train and evaluate Keras models?",
        answer: "<strong>Training and evaluation process:</strong><br><br><code># Training<br>history = model.fit(<br>&nbsp;&nbsp;&nbsp;&nbsp;X_train, y_train,<br>&nbsp;&nbsp;&nbsp;&nbsp;validation_data=(X_valid, y_valid),<br>&nbsp;&nbsp;&nbsp;&nbsp;batch_size=256,<br>&nbsp;&nbsp;&nbsp;&nbsp;epochs=50<br>)<br><br># Evaluation<br>loss, accuracy = model.evaluate(X_test, y_test)<br>predictions = model.predict(X_test)</code>",
        hint: "üèÉ‚Äç‚ôÇÔ∏è fit() = train, evaluate() = performance, predict() = predictions",
        image: ""
    },
    {
        question: "How does learning rate affect training and what are good starting values?",
        answer: "<strong>Learning rate effects:</strong><br><br>‚Ä¢ <strong>Too high:</strong> Training unstable, loss explodes<br>‚Ä¢ <strong>Too low:</strong> Very slow training, may get stuck<br><br><strong>Good starting points:</strong><br>‚Ä¢ 0.01 for SGD<br>‚Ä¢ 0.001 for Adam<br><br><strong>Best practice:</strong> Use adaptive optimizers like Adam",
        hint: "‚ö° Start with 0.001 for Adam, 0.01 for SGD",
        image: ""
    },
    {
        question: "List key strategies to prevent overfitting",
        answer: "<strong>Overfitting prevention strategies:</strong><br><br>1. <strong>Early stopping:</strong> Stop when validation performance stops improving<br>2. <strong>Dropout:</strong> Randomly disable neurons during training<br>3. <strong>Batch normalization:</strong> Normalize layer inputs<br>4. <strong>Reduce model complexity:</strong> Fewer layers/units<br>5. <strong>Data augmentation:</strong> Increase training data variety<br>6. <strong>Regularization:</strong> Add L1/L2 penalty terms",
        hint: "üõ°Ô∏è Multiple defenses work better than single approach",
        image: ""
    },
    {
        question: "What should you check when your neural network performs poorly?",
        answer: "<strong>Debugging checklist:</strong><br><br>1. <strong>Data quality:</strong> Errors, missing values, preprocessing<br>2. <strong>Model capacity:</strong> Too simple (underfitting) or complex (overfitting)<br>3. <strong>Learning rate:</strong> Too high/low<br>4. <strong>Loss function:</strong> Appropriate for your task<br>5. <strong>Training time:</strong> Sufficient epochs vs early stopping<br>6. <strong>Feature scaling:</strong> Normalize/standardize inputs",
        hint: "üîç Systematic debugging: data ‚Üí model ‚Üí training ‚Üí evaluation",
        image: ""
    },
    {
        question: "Why is neural network training computationally expensive?",
        answer: "<strong>Training computational expense:</strong><br><br>Training repeatedly processes data points, calculates errors, and updates weights through gradient descent <strong>thousands of times</strong> across multiple epochs.<br><br>For large models like LLMs, this can take <strong>months with thousands of GPUs</strong>, but the principle remains the same as simple networks.",
        hint: "üí∞ Thousands of iterations √ó Multiple epochs = Expensive computation",
        image: ""
    },
    {
        question: "How can you simplify complex ML terminology?",
        answer: "<strong>Academic language translation:</strong><br><br>Academic language is often 'standardizable but ununderstandable':<br><br>‚Ä¢ <strong>'Stochastic Gradient Descent'</strong> = 'Random error minimization'<br>‚Ä¢ <strong>'Gradient descent'</strong> = 'Rolling ball finding lowest point'<br>‚Ä¢ <strong>'Model capacity'</strong> = 'Network intelligence'<br><br>The concepts are simpler than the terminology suggests.",
        hint: "üó£Ô∏è Translate academic jargon into simple, understandable concepts",
        image: ""
    },
    {
        question: "Why is computer vision challenging for machines despite seeming easy for humans?",
        answer: "<strong>Computer vision complexity:</strong><br><br>For machines, images are just <strong>numbers and probabilities</strong>. Even simple 28x28 pixel classification is computationally intensive.<br><br>Our brain's visual cortex (V1, V2, V3, V4) processes images through <strong>multiple layers of increasing complexity</strong> - neural networks copy this hierarchical structure.",
        hint: "üëÅÔ∏è Human vision = complex brain hierarchy, machines copy this structure",
        image: ""
    },
    {
        question: "What information does model.summary() provide?",
        answer: "<strong>model.summary() information:</strong><br><br>Shows <strong>output shape</strong> of each layer (neurons) and <strong>number of parameters</strong> (weights + biases).<br><br><strong>Calculation example:</strong> Layer with 32 neurons and 3 inputs = 32√ó3 weights + 32 biases = 128 total parameters.<br><br>This helps understand model complexity and computational requirements.",
        hint: "üìä Summary = layer shapes + parameter count for complexity understanding",
        image: ""
    },
    {
        question: "What's the best approach for learning deep learning?",
        answer: "<strong>Effective learning strategy:</strong><br><br>1. <strong>Start with conceptual understanding:</strong> Use good visualizations<br>2. <strong>Don't rush:</strong> Split learning across 3-4 days<br>3. <strong>Balance theory and practice:</strong> Combine conceptual learning with hands-on coding<br>4. <strong>Focus on intuition first:</strong> Understand concepts before complex implementations<br>5. <strong>Use multiple approaches:</strong> Visualizations for concepts, then code for practice",
        hint: "üéØ Concepts first ‚Üí Practice second ‚Üí Balance both approaches",
        image: ""
    }
];

        function createCard(card, index) {
            return `
                <div class="flashcard">
                    <div class="card-number">${index + 1}</div>
                    <div class="card-header">
                        <div class="card-question">${card.question}</div>
                    </div>
                    
                    ${card.image && card.image.trim() !== '' ? `
                        <div class="card-image-container">
                            <img src="${card.image}" alt="Learning content" />
                        </div>
                    ` : ''}
                    
                    <div class="card-body">
                        <div class="answer-section">
                            <div class="answer-label">Answer</div>
                            <div class="card-answer">${card.answer}</div>
                        </div>
                        
                        ${card.hint ? `
                            <div class="card-hint">${card.hint}</div>
                        ` : ''}
                    </div>
                </div>
            `;
        }

        function renderCards() {
            const cardsContainer = document.getElementById('cardsContainer');
            const cardsHTML = flashcards.map((card, index) => createCard(card, index)).join('');
            cardsContainer.innerHTML = cardsHTML;
        }

        // Initialize cards on page load
        document.addEventListener('DOMContentLoaded', renderCards);
    </script>
</body>
</html>
