<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI/ML Flash Cards</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .flashcard-container {
            max-width: 600px;
            width: 100%;
        }

        .header {
            text-align: center;
            margin-bottom: 30px;
            color: white;
        }

        .header h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 10px;
        }

        .progress {
            background: rgba(255, 255, 255, 0.2);
            border-radius: 10px;
            padding: 8px;
            margin-bottom: 20px;
        }

        .progress-bar {
            background: #4CAF50;
            height: 8px;
            border-radius: 4px;
            transition: width 0.3s ease;
        }

        .progress-text {
            color: white;
            font-size: 0.9rem;
            margin-top: 5px;
        }

        .flashcard {
            perspective: 1000px;
            margin-bottom: 20px;
        }

        .flashcard-inner {
            position: relative;
            width: 100%;
            height: 400px;
            transition: transform 0.6s;
            transform-style: preserve-3d;
            cursor: pointer;
        }

        .flashcard.flipped .flashcard-inner {
            transform: rotateY(180deg);
        }

        .flashcard-front, .flashcard-back {
            position: absolute;
            width: 100%;
            height: 100%;
            backface-visibility: hidden;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .flashcard-front {
            background: white;
        }

        .flashcard-back {
            background: #f8f9fa;
            transform: rotateY(180deg);
        }

        .card-image {
            height: 200px;
            width: 100%;
            object-fit: cover;
            background: #e9ecef;
        }

        .card-content {
            padding: 25px;
            flex: 1;
            display: flex;
            flex-direction: column;
            justify-content: center;
        }

        .card-category {
            background: #667eea;
            color: white;
            padding: 4px 12px;
            border-radius: 15px;
            font-size: 0.8rem;
            font-weight: 600;
            align-self: flex-start;
            margin-bottom: 15px;
        }

        .card-question {
            font-size: 1.3rem;
            font-weight: 600;
            color: #333;
            line-height: 1.4;
        }

        .card-answer {
            font-size: 1.1rem;
            color: #555;
            line-height: 1.6;
        }

        .card-hint {
            background: #e3f2fd;
            border-left: 4px solid #2196F3;
            padding: 10px 15px;
            margin-top: 15px;
            border-radius: 5px;
            font-style: italic;
            color: #1976D2;
        }

        .controls {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-top: 25px;
            gap: 15px;
        }

        .btn {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 1rem;
        }

        .btn-primary {
            background: #4CAF50;
            color: white;
        }

        .btn-secondary {
            background: white;
            color: #333;
            border: 2px solid #ddd;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        .navigation {
            display: flex;
            gap: 10px;
        }

        .flip-hint {
            text-align: center;
            color: rgba(255, 255, 255, 0.8);
            font-size: 0.9rem;
            margin-top: 10px;
        }

        /* Mobile Responsiveness */
        @media (max-width: 480px) {
            .header h1 {
                font-size: 2rem;
            }
            
            .flashcard-inner {
                height: 350px;
            }
            
            .card-image {
                height: 150px;
            }
            
            .card-content {
                padding: 20px;
            }
            
            .card-question {
                font-size: 1.1rem;
            }
            
            .card-answer {
                font-size: 1rem;
            }
            
            .controls {
                flex-direction: column;
                gap: 10px;
            }
            
            .navigation {
                width: 100%;
                justify-content: center;
            }
        }

        .no-image {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 3rem;
        }
    </style>
</head>
<body>
    <div class="flashcard-container">
        <div class="header">
            <h1>AI/ML Flash Cards</h1>
            <div class="progress">
                <div class="progress-bar" id="progressBar"></div>
                <div class="progress-text" id="progressText">Card 1 of 3</div>
            </div>
        </div>

        <div class="flashcard" id="flashcard">
            <div class="flashcard-inner">
                <div class="flashcard-front">
                    <div class="card-image no-image" id="frontImage">ü§ñ</div>
                    <div class="card-content">
                        <div class="card-category" id="category">AI Fundamentals</div>
                        <div class="card-question" id="question">What is the difference between supervised and unsupervised learning?</div>
                    </div>
                </div>
                <div class="flashcard-back">
                    <div class="card-image no-image" id="backImage">üìä</div>
                    <div class="card-content">
                        <div class="card-answer" id="answer">
                            <strong>Supervised Learning:</strong> Uses labeled training data to learn patterns and make predictions (e.g., classification, regression).<br><br>
                            <strong>Unsupervised Learning:</strong> Finds hidden patterns in unlabeled data without target outputs (e.g., clustering, dimensionality reduction).
                        </div>
                        <div class="card-hint">üí° Think: Supervised = teacher guides learning, Unsupervised = self-discovery</div>
                    </div>
                </div>
            </div>
        </div>

        <div class="flip-hint">Click card to flip</div>

        <div class="controls">
            <button class="btn btn-secondary" id="prevBtn">‚Üê Previous</button>
            <button class="btn btn-primary" id="flipBtn">Flip Card</button>
            <div class="navigation">
                <button class="btn btn-secondary" id="shuffleBtn">üîÄ Shuffle</button>
                <button class="btn btn-secondary" id="nextBtn">Next ‚Üí</button>
            </div>
        </div>
    </div>

    <!-- CARDS DATA - ADD YOUR CARDS HERE -->
    <script>
        // Deep Learning Flashcards - Ready to paste into your HTML file
// Replace the flashcards array in your HTML with this one

const flashcards = [
    {
        category: "Deep Learning Fundamentals",
        question: "What is deep learning and what characterizes it?",
        answer: "Deep learning is an approach to machine learning characterized by <strong>deep stacks of computations</strong>. This depth enables models to disentangle complex and hierarchical patterns in challenging real-world data, leading to human-level or superhuman performance in tasks like natural language translation, image recognition, and game playing.",
        hint: "üß† Think: Deep = many layers of computation stacked together",
        frontImage: "",
        backImage: "",
        frontEmoji: "üß†",
        backEmoji: "ü§ñ"
    },
    {
        category: "Neural Network Basics",
        question: "What is a linear unit (neuron) and what does it compute?",
        answer: "A linear unit is the building block of neural networks. It computes a <strong>linear function</strong>: <code>y = wx + b</code><br><br>Where:<br>‚Ä¢ <strong>w</strong> = weight<br>‚Ä¢ <strong>x</strong> = input<br>‚Ä¢ <strong>b</strong> = bias<br><br>Multiple inputs: <code>y = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + ... + w‚Çôx‚Çô + b</code>",
        hint: "‚ö° Remember: Weight √ó Input + Bias = Output",
        frontImage: "",
        backImage: "",
        frontEmoji: "‚ö°",
        backEmoji: "üî¢"
    },
    {
        category: "Keras Programming",
        question: "How do you create a simple linear model in Keras?",
        answer: "<strong>Basic Keras model structure:</strong><br><br><code>from tensorflow import keras<br>from tensorflow.keras import layers<br><br>model = keras.Sequential([<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(units=1, input_shape=[3])<br>])</code><br><br>This creates a model with <strong>1 output unit</strong> accepting <strong>3 input features</strong>.",
        hint: "üíª Sequential = simple stack of layers",
        frontImage: "",
        backImage: "",
        frontEmoji: "üíª",
        backEmoji: "üîß"
    },
    {
        category: "Keras Programming",
        question: "What does input_shape=[3] mean in Keras?",
        answer: "It tells Keras that the model will accept <strong>3 features as input</strong>. For tabular data, this represents the number of columns/features in your dataset.<br><br>Example: If your data has columns [age, income, score], then input_shape=[3].",
        hint: "üìä Input shape = number of columns/features in your data",
        frontImage: "",
        backImage: "",
        frontEmoji: "üìä",
        backEmoji: "üìã"
    },
    {
        category: "Deep Learning Architecture",
        question: "What are hidden layers and why are they important?",
        answer: "Hidden layers are layers <strong>between input and output layers</strong>. They allow neural networks to learn <strong>complex, non-linear relationships</strong> by stacking multiple linear units and applying activation functions.<br><br><strong>Without hidden layers:</strong> Only linear relationships possible<br><strong>With hidden layers:</strong> Complex patterns and non-linear relationships",
        hint: "üîó Hidden layers = the secret sauce for complex patterns",
        frontImage: "",
        backImage: "",
        frontEmoji: "üîó",
        backEmoji: "üåê"
    },
    {
        category: "Activation Functions",
        question: "What is the ReLU activation function and why is it commonly used?",
        answer: "<strong>ReLU (Rectified Linear Unit):</strong> <code>max(0, x)</code><br><br><strong>Function:</strong> Outputs input if positive, otherwise 0<br><br><strong>Why popular:</strong><br>‚Ä¢ Computationally efficient<br>‚Ä¢ Helps with vanishing gradient problem<br>‚Ä¢ Enables learning of non-linear patterns<br>‚Ä¢ Simple but effective",
        hint: "üöÄ ReLU: If positive, pass through; if negative, make zero",
        frontImage: "",
        backImage: "",
        frontEmoji: "üöÄ",
        backEmoji: "üìà"
    },
    {
        category: "Activation Functions",
        question: "Name three alternatives to ReLU and their characteristics.",
        answer: "<strong>Three ReLU alternatives:</strong><br><br>‚Ä¢ <strong>ELU (Exponential Linear Unit):</strong> Smooth for negative values, can output negative values<br><br>‚Ä¢ <strong>SELU (Scaled ELU):</strong> Self-normalizing properties, good for deep networks<br><br>‚Ä¢ <strong>Swish:</strong> Smooth, non-monotonic function that can outperform ReLU in some cases",
        hint: "üîÑ Each activation has its own strengths for different scenarios",
        frontImage: "",
        backImage: "",
        frontEmoji: "üîÑ",
        backEmoji: "‚öôÔ∏è"
    },
    {
        category: "Keras Programming",
        question: "How do you create a deep neural network with hidden layers in Keras?",
        answer: "<strong>Deep network example:</strong><br><br><code>model = keras.Sequential([<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(units=4, activation='relu', input_shape=[2]),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(units=3, activation='relu'),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(units=1)<br>])</code><br><br>This creates a network with:<br>‚Ä¢ Two hidden layers (4 and 3 units)<br>‚Ä¢ One output layer",
        hint: "üèóÔ∏è Stack layers like building blocks: Input ‚Üí Hidden ‚Üí Hidden ‚Üí Output",
        frontImage: "",
        backImage: "",
        frontEmoji: "üèóÔ∏è",
        backEmoji: "üî®"
    },
    {
        category: "Training & Optimization",
        question: "What is Stochastic Gradient Descent and how does it work?",
        answer: "<strong>SGD</strong> is an optimization algorithm that updates model weights using <strong>small random samples (minibatches)</strong> instead of the entire dataset.<br><br><strong>Process:</strong><br>‚Ä¢ Take random sample of training data<br>‚Ä¢ Calculate gradients<br>‚Ä¢ Update weights to minimize loss<br>‚Ä¢ Repeat<br><br><strong>Benefits:</strong> Faster training, often more robust",
        hint: "üéØ SGD: Small steps using small batches = efficient learning",
        frontImage: "",
        backImage: "",
        frontEmoji: "üéØ",
        backEmoji: "üìâ"
    },
    {
        category: "Training & Optimization",
        question: "Define minibatch and epoch in neural network training.",
        answer: "<strong>Key training terminology:</strong><br><br>‚Ä¢ <strong>Minibatch (or batch):</strong> A small random sample of training data used in one iteration of SGD<br><br>‚Ä¢ <strong>Epoch:</strong> One complete pass through the entire training dataset<br><br>Example: 1000 samples, batch size 100 = 10 batches per epoch",
        hint: "üîÑ Batch = small sample, Epoch = full dataset pass",
        frontImage: "",
        backImage: "",
        frontEmoji: "üîÑ",
        backEmoji: "üìö"
    },
    {
        category: "Loss Functions",
        question: "Name three common loss functions for regression tasks and when to use them.",
        answer: "<strong>Regression loss functions:</strong><br><br>‚Ä¢ <strong>MAE (Mean Absolute Error):</strong> Less sensitive to outliers, measures average absolute differences<br><br>‚Ä¢ <strong>MSE (Mean Squared Error):</strong> Penalizes larger errors more heavily, smooth gradient<br><br>‚Ä¢ <strong>Huber Loss:</strong> Combines MAE and MSE benefits, robust to outliers while maintaining smoothness",
        hint: "üìè Choose based on how you want to handle outliers",
        frontImage: "",
        backImage: "",
        frontEmoji: "üìè",
        backEmoji: "üéØ"
    },
    {
        category: "Training & Optimization",
        question: "Compare SGD and Adam optimizers.",
        answer: "<strong>SGD vs Adam:</strong><br><br><strong>SGD:</strong><br>‚Ä¢ Simple algorithm<br>‚Ä¢ Uses fixed learning rate<br>‚Ä¢ Can be slow but reliable<br><br><strong>Adam:</strong><br>‚Ä¢ Adaptive learning rates<br>‚Ä¢ Faster convergence<br>‚Ä¢ Combines momentum with adaptive learning<br>‚Ä¢ Generally preferred for most applications",
        hint: "üèÉ‚Äç‚ôÇÔ∏è Adam = smarter, adaptive SGD for faster training",
        frontImage: "",
        backImage: "",
        frontEmoji: "üèÉ‚Äç‚ôÇÔ∏è",
        backEmoji: "‚ö°"
    },
    {
        category: "Keras Programming",
        question: "How do you compile a Keras model for training?",
        answer: "<strong>Model compilation syntax:</strong><br><br><code>model.compile(<br>&nbsp;&nbsp;&nbsp;&nbsp;optimizer='adam',<br>&nbsp;&nbsp;&nbsp;&nbsp;loss='mae',<br>&nbsp;&nbsp;&nbsp;&nbsp;metrics=['mae']<br>)</code><br><br><strong>Required components:</strong><br>‚Ä¢ <strong>Optimizer:</strong> How to update weights<br>‚Ä¢ <strong>Loss function:</strong> What to minimize<br>‚Ä¢ <strong>Metrics:</strong> What to track during training",
        hint: "‚öôÔ∏è Compile = configure the training process",
        frontImage: "",
        backImage: "",
        frontEmoji: "‚öôÔ∏è",
        backEmoji: "üîß"
    },
    {
        category: "Model Performance",
        question: "What is overfitting and what are its signs?",
        answer: "<strong>Overfitting:</strong> Model learns training data too well, including noise and irrelevant patterns.<br><br><strong>Signs of overfitting:</strong><br>‚Ä¢ High training accuracy, poor validation/test performance<br>‚Ä¢ Training loss decreases while validation loss increases<br>‚Ä¢ Large gap between training and validation metrics",
        hint: "üìàüìâ Good on training, bad on new data = overfitting",
        frontImage: "",
        backImage: "",
        frontEmoji: "üìà",
        backEmoji: "‚ö†Ô∏è"
    },
    {
        category: "Model Performance",
        question: "What is underfitting and how can you identify it?",
        answer: "<strong>Underfitting:</strong> Model is too simple to capture underlying data patterns.<br><br><strong>Signs of underfitting:</strong><br>‚Ä¢ Poor performance on both training and validation sets<br>‚Ä¢ Loss plateaus at high value for both training and validation<br>‚Ä¢ Model seems too simple for the task complexity",
        hint: "üò¥ Poor everywhere = underfitting (model too simple)",
        frontImage: "",
        backImage: "",
        frontEmoji: "üò¥",
        backEmoji: "üìä"
    },
    {
        category: "Model Performance",
        question: "What is model capacity and how does it relate to overfitting/underfitting?",
        answer: "<strong>Model capacity:</strong> The complexity and size of a model (number of parameters).<br><br><strong>Relationship:</strong><br>‚Ä¢ <strong>Low capacity:</strong> Leads to underfitting<br>‚Ä¢ <strong>High capacity:</strong> Can lead to overfitting<br>‚Ä¢ <strong>Goal:</strong> Find the right capacity for optimal generalization",
        hint: "‚öñÔ∏è Goldilocks principle: not too simple, not too complex",
        frontImage: "",
        backImage: "",
        frontEmoji: "‚öñÔ∏è",
        backEmoji: "üéØ"
    },
    {
        category: "Regularization",
        question: "What is early stopping and how does it prevent overfitting?",
        answer: "<strong>Early stopping:</strong> Monitors validation performance and stops training when validation loss starts increasing while training loss continues decreasing.<br><br><strong>Prevention mechanism:</strong><br>‚Ä¢ Stops at point of best generalization<br>‚Ä¢ Prevents model from memorizing training data<br>‚Ä¢ Automatic regularization technique",
        hint: "üõë Stop training at the sweet spot before overfitting begins",
        frontImage: "",
        backImage: "",
        frontEmoji: "üõë",
        backEmoji: "üìà"
    },
    {
        category: "Model Performance",
        question: "How can you increase model capacity in neural networks?",
        answer: "<strong>Ways to increase capacity:</strong><br><br>‚Ä¢ <strong>Add more hidden layers</strong> (making it deeper)<br>‚Ä¢ <strong>Add more units to existing layers</strong> (making it wider)<br>‚Ä¢ <strong>Combine both approaches</strong><br><br>Both methods add more parameters for the model to learn complex patterns.",
        hint: "üìèüìê Wider layers OR deeper network OR both = more capacity",
        frontImage: "",
        backImage: "",
        frontEmoji: "üìè",
        backEmoji: "üèóÔ∏è"
    },
    {
        category: "Regularization",
        question: "What is dropout and how does it prevent overfitting?",
        answer: "<strong>Dropout:</strong> Randomly sets a fraction of input units to 0 during training.<br><br><strong>Prevention mechanism:</strong><br>‚Ä¢ Prevents over-dependence on specific neurons<br>‚Ä¢ Forces learning of more robust features<br>‚Ä¢ Creates ensemble effect<br>‚Ä¢ Only applied during training, not inference",
        hint: "üé≤ Randomly 'turn off' neurons to prevent over-reliance",
        frontImage: "",
        backImage: "",
        frontEmoji: "üé≤",
        backEmoji: "üõ°Ô∏è"
    },
    {
        category: "Keras Programming",
        question: "How do you add dropout to a Keras model?",
        answer: "<strong>Dropout implementation:</strong><br><br><code>model = keras.Sequential([<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(512, activation='relu'),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dropout(0.3),  # 30% dropout rate<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(1)<br>])</code><br><br>The dropout layer is typically placed <strong>after Dense layers</strong>.",
        hint: "üíß Add Dropout layer after Dense layers with a rate (e.g., 0.3 = 30%)",
        frontImage: "",
        backImage: "",
        frontEmoji: "üíß",
        backEmoji: "üîß"
    },
    {
        category: "Regularization",
        question: "What is batch normalization and what problems does it solve?",
        answer: "<strong>Batch normalization:</strong> Normalizes inputs to each layer, making training more stable and faster.<br><br><strong>Problems it solves:</strong><br>‚Ä¢ Internal covariate shift<br>‚Ä¢ Vanishing/exploding gradients<br>‚Ä¢ Allows higher learning rates<br>‚Ä¢ Acts as mild regularizer",
        hint: "üîÑ Normalize layer inputs = stable, faster training",
        frontImage: "",
        backImage: "",
        frontEmoji: "üîÑ",
        backEmoji: "‚ö°"
    },
    {
        category: "Keras Programming",
        question: "How do you add batch normalization to a Keras model?",
        answer: "<strong>Batch normalization implementation:</strong><br><br><code>model = keras.Sequential([<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(512),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.BatchNormalization(),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Activation('relu'),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(1)<br>])</code><br><br>BatchNormalization is typically applied <strong>before the activation function</strong>.",
        hint: "üìä Order: Dense ‚Üí BatchNorm ‚Üí Activation",
        frontImage: "",
        backImage: "",
        frontEmoji: "üìä",
        backEmoji: "üîß"
    },
    {
        category: "Regularization",
        question: "In what order should you apply Dense layers, Batch Normalization, Dropout, and Activation?",
        answer: "<strong>Typical order:</strong> Dense ‚Üí Batch Normalization ‚Üí Activation ‚Üí Dropout<br><br><code>layers.Dense(units),<br>layers.BatchNormalization(),<br>layers.Activation('relu'),<br>layers.Dropout(rate)</code><br><br>This order optimizes training stability and regularization effectiveness.",
        hint: "üî¢ Remember: Dense ‚Üí BatchNorm ‚Üí Activation ‚Üí Dropout",
        frontImage: "",
        backImage: "",
        frontEmoji: "üî¢",
        backEmoji: "üìã"
    },
    {
        category: "Binary Classification",
        question: "How does binary classification differ from regression in neural networks?",
        answer: "<strong>Key differences:</strong><br><br><strong>Binary Classification:</strong><br>‚Ä¢ Predicts one of two classes (0 or 1)<br>‚Ä¢ Uses sigmoid activation in output layer<br>‚Ä¢ Uses binary crossentropy loss<br><br><strong>Regression:</strong><br>‚Ä¢ Predicts continuous values<br>‚Ä¢ No activation (linear) in output layer<br>‚Ä¢ Uses MSE/MAE loss",
        hint: "üéØ Classification = categories, Regression = continuous numbers",
        frontImage: "",
        backImage: "",
        frontEmoji: "üéØ",
        backEmoji: "üìä"
    },
    {
        category: "Activation Functions",
        question: "What is the sigmoid activation function and why is it used for binary classification?",
        answer: "<strong>Sigmoid function:</strong> œÉ(x) = 1/(1 + e^(-x))<br><br><strong>Properties:</strong><br>‚Ä¢ Maps any real number to value between 0 and 1<br>‚Ä¢ Perfect for representing probabilities<br>‚Ä¢ Output can be interpreted as probability of positive class<br>‚Ä¢ Smooth, differentiable function",
        hint: "üìà Sigmoid squashes any number into 0-1 probability range",
        frontImage: "",
        backImage: "",
        frontEmoji: "üìà",
        backEmoji: "üé≤"
    },
    {
        category: "Loss Functions",
        question: "What is binary crossentropy and when is it used?",
        answer: "<strong>Binary crossentropy:</strong> Standard loss function for binary classification.<br><br><strong>Formula:</strong> -[y*log(p) + (1-y)*log(1-p)]<br>Where y = true label, p = predicted probability<br><br><strong>Purpose:</strong> Measures difference between predicted probabilities and true binary labels",
        hint: "üìè Measures how far predicted probabilities are from true labels",
        frontImage: "",
        backImage: "",
        frontEmoji: "üìè",
        backEmoji: "üéØ"
    },
    {
        category: "Keras Programming",
        question: "How do you create a binary classification model in Keras?",
        answer: "<strong>Binary classification model:</strong><br><br><code>model = keras.Sequential([<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(4, activation='relu', input_shape=[33]),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(4, activation='relu'),<br>&nbsp;&nbsp;&nbsp;&nbsp;layers.Dense(1, activation='sigmoid')  # sigmoid for binary<br>])<br><br>model.compile(<br>&nbsp;&nbsp;&nbsp;&nbsp;optimizer='adam',<br>&nbsp;&nbsp;&nbsp;&nbsp;loss='binary_crossentropy',<br>&nbsp;&nbsp;&nbsp;&nbsp;metrics=['binary_accuracy']<br>)</code>",
        hint: "üîß Key: sigmoid output + binary_crossentropy loss",
        frontImage: "",
        backImage: "",
        frontEmoji: "üîß",
        backEmoji: "üéØ"
    },
    {
        category: "Keras Programming",
        question: "What is keras.Sequential and when should you use it?",
        answer: "<strong>keras.Sequential:</strong> Easiest way to create neural networks in Keras.<br><br><strong>Characteristics:</strong><br>‚Ä¢ Creates linear stack of layers<br>‚Ä¢ Each layer has one input and one output<br>‚Ä¢ Data flows sequentially through layers<br><br><strong>Use when:</strong> Simple, straightforward architectures with linear flow",
        hint: "üìö Sequential = simple stack of layers, one after another",
        frontImage: "",
        backImage: "",
        frontEmoji: "üìö",
        backEmoji: "üîó"
    },
    {
        category: "Keras Programming",
        question: "What does layers.Dense represent and what are its key parameters?",
        answer: "<strong>layers.Dense:</strong> Fully-connected layer where each input connects to each output.<br><br><strong>Key parameters:</strong><br>‚Ä¢ <strong>units:</strong> number of neurons/outputs<br>‚Ä¢ <strong>activation:</strong> activation function to apply<br>‚Ä¢ <strong>input_shape:</strong> shape of input data (only needed for first layer)",
        hint: "üï∏Ô∏è Dense = every input connected to every output",
        frontImage: "",
        backImage: "",
        frontEmoji: "üï∏Ô∏è",
        backEmoji: "üîß"
    },
    {
        category: "Keras Programming",
        question: "How do you train a Keras model?",
        answer: "<strong>Model training with fit():</strong><br><br><code>history = model.fit(<br>&nbsp;&nbsp;&nbsp;&nbsp;X_train, y_train,<br>&nbsp;&nbsp;&nbsp;&nbsp;validation_data=(X_valid, y_valid),<br>&nbsp;&nbsp;&nbsp;&nbsp;batch_size=256,<br>&nbsp;&nbsp;&nbsp;&nbsp;epochs=50,<br>&nbsp;&nbsp;&nbsp;&nbsp;verbose=0  # suppress output<br>)</code><br><br><code>fit()</code> trains the model and returns training history.",
        hint: "üèÉ‚Äç‚ôÇÔ∏è fit() does the actual training work",
        frontImage: "",
        backImage: "",
        frontEmoji: "üèÉ‚Äç‚ôÇÔ∏è",
        backEmoji: "üìà"
    },
    {
        category: "Keras Programming",
        question: "How do you evaluate model performance in Keras?",
        answer: "<strong>Model evaluation methods:</strong><br><br><strong>Get loss and metrics:</strong><br><code>loss, accuracy = model.evaluate(X_test, y_test)</code><br><br><strong>Make predictions:</strong><br><code>predictions = model.predict(X_test)</code><br><br>Use <code>evaluate()</code> for final performance, <code>predict()</code> for actual predictions.",
        hint: "üìä evaluate() = performance metrics, predict() = actual predictions",
        frontImage: "",
        backImage: "",
        frontEmoji: "üìä",
        backEmoji: "üéØ"
    },
    {
        category: "Best Practices",
        question: "When should you use different activation functions?",
        answer: "<strong>Activation function guidelines:</strong><br><br>‚Ä¢ <strong>ReLU:</strong> Default for hidden layers, fast and effective<br>‚Ä¢ <strong>Sigmoid:</strong> Output layer for binary classification<br>‚Ä¢ <strong>Softmax:</strong> Output layer for multi-class classification<br>‚Ä¢ <strong>Linear (no activation):</strong> Output layer for regression<br>‚Ä¢ <strong>ELU/SELU:</strong> When you need smooth derivatives",
        hint: "üéõÔ∏è Choose activation based on layer position and task type",
        frontImage: "",
        backImage: "",
        frontEmoji: "üéõÔ∏è",
        backEmoji: "‚öôÔ∏è"
    },
    {
        category: "Best Practices",
        question: "How does learning rate affect training and what are good starting values?",
        answer: "<strong>Learning rate effects:</strong><br><br>‚Ä¢ <strong>Too high:</strong> Training unstable, loss explodes<br>‚Ä¢ <strong>Too low:</strong> Very slow training, may get stuck<br><br><strong>Good starting points:</strong><br>‚Ä¢ <strong>SGD:</strong> 0.01<br>‚Ä¢ <strong>Adam:</strong> 0.001<br><br>Use learning rate scheduling or adaptive optimizers for best results.",
        hint: "‚ö° Start with 0.001 for Adam, 0.01 for SGD",
        frontImage: "",
        backImage: "",
        frontEmoji: "‚ö°",
        backEmoji: "üéØ"
    },
    {
        category: "Best Practices",
        question: "List five strategies to prevent overfitting in deep learning.",
        answer: "<strong>Overfitting prevention strategies:</strong><br><br>1. <strong>Early stopping:</strong> Stop when validation performance stops improving<br>2. <strong>Dropout:</strong> Randomly disable neurons during training<br>3. <strong>Batch normalization:</strong> Normalize layer inputs<br>4. <strong>Reduce model complexity:</strong> Fewer layers/units<br>5. <strong>Data augmentation:</strong> Increase training data variety",
        hint: "üõ°Ô∏è Multiple defenses work better than single approach",
        frontImage: "",
        backImage: "",
        frontEmoji: "üõ°Ô∏è",
        backEmoji: "‚öîÔ∏è"
    },
    {
        category: "Best Practices",
        question: "What should you check when your neural network performs poorly?",
        answer: "<strong>Debugging checklist:</strong><br><br>1. <strong>Data quality:</strong> Errors, missing values, proper preprocessing<br>2. <strong>Model capacity:</strong> Too simple (underfitting) or too complex (overfitting)<br>3. <strong>Learning rate:</strong> Too high or too low<br>4. <strong>Loss function:</strong> Appropriate for your task<br>5. <strong>Training time:</strong> Enough epochs vs early stopping<br>6. <strong>Feature scaling:</strong> Normalize/standardize inputs",
        hint: "üîç Systematic debugging: data ‚Üí model ‚Üí training ‚Üí evaluation",
        frontImage: "",
        backImage: "",
        frontEmoji: "üîç",
        backEmoji: "üõ†Ô∏è"
    }
];

        let currentCard = 0;
        let isFlipped = false;

        // DOM elements
        const flashcard = document.getElementById('flashcard');
        const category = document.getElementById('category');
        const question = document.getElementById('question');
        const answer = document.getElementById('answer');
        const frontImage = document.getElementById('frontImage');
        const backImage = document.getElementById('backImage');
        const progressBar = document.getElementById('progressBar');
        const progressText = document.getElementById('progressText');
        const prevBtn = document.getElementById('prevBtn');
        const nextBtn = document.getElementById('nextBtn');
        const flipBtn = document.getElementById('flipBtn');
        const shuffleBtn = document.getElementById('shuffleBtn');

        function updateCard() {
            const card = flashcards[currentCard];
            
            // Update content
            category.textContent = card.category;
            question.textContent = card.question;
            answer.innerHTML = card.answer;
            
            // Update images or emojis
            if (card.frontImage) {
                frontImage.innerHTML = `<img src="${card.frontImage}" alt="Card image" style="width:100%;height:100%;object-fit:cover;">`;
                frontImage.classList.remove('no-image');
            } else {
                frontImage.textContent = card.frontEmoji || 'üéì';
                frontImage.classList.add('no-image');
            }
            
            if (card.backImage) {
                backImage.innerHTML = `<img src="${card.backImage}" alt="Card image" style="width:100%;height:100%;object-fit:cover;">`;
                backImage.classList.remove('no-image');
            } else {
                backImage.textContent = card.backEmoji || 'üí°';
                backImage.classList.add('no-image');
            }
            
            // Add hint if exists
            const existingHint = document.querySelector('.card-hint');
            if (existingHint) existingHint.remove();
            
            if (card.hint) {
                const hintDiv = document.createElement('div');
                hintDiv.className = 'card-hint';
                hintDiv.textContent = card.hint;
                document.querySelector('.flashcard-back .card-content').appendChild(hintDiv);
            }
            
            // Update progress
            const progress = ((currentCard + 1) / flashcards.length) * 100;
            progressBar.style.width = progress + '%';
            progressText.textContent = `Card ${currentCard + 1} of ${flashcards.length}`;
            
            // Reset flip state
            isFlipped = false;
            flashcard.classList.remove('flipped');
            flipBtn.textContent = 'Flip Card';
        }

        function flipCard() {
            isFlipped = !isFlipped;
            flashcard.classList.toggle('flipped');
            flipBtn.textContent = isFlipped ? 'Show Question' : 'Show Answer';
        }

        function nextCard() {
            currentCard = (currentCard + 1) % flashcards.length;
            updateCard();
        }

        function prevCard() {
            currentCard = (currentCard - 1 + flashcards.length) % flashcards.length;
            updateCard();
        }

        function shuffleCards() {
            for (let i = flashcards.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [flashcards[i], flashcards[j]] = [flashcards[j], flashcards[i]];
            }
            currentCard = 0;
            updateCard();
        }

        // Event listeners
        flashcard.addEventListener('click', flipCard);
        flipBtn.addEventListener('click', flipCard);
        nextBtn.addEventListener('click', nextCard);
        prevBtn.addEventListener('click', prevCard);
        shuffleBtn.addEventListener('click', shuffleCards);

        // Keyboard navigation
        document.addEventListener('keydown', (e) => {
            switch(e.key) {
                case 'ArrowLeft':
                    prevCard();
                    break;
                case 'ArrowRight':
                    nextCard();
                    break;
                case ' ':
                case 'Enter':
                    e.preventDefault();
                    flipCard();
                    break;
            }
        });

        // Initialize
        updateCard();
    </script>
</body>
</html>
